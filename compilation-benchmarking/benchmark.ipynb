{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial setup\n",
    "import qiskit\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from benchmark import run_benchmark_sample, Trials\n",
    "\n",
    "load_dotenv()\n",
    "API_TOKEN = os.getenv(\"API_TOKEN\")\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\", token=API_TOKEN)\n",
    "backend = service.backend(name=\"ibm_rensselaer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(include_existing_trials=True):\n",
    "    for num_vars in range(2, 30):\n",
    "        for complexity in range(1, 30):\n",
    "            run_benchmark_sample(num_vars, complexity, num_functions=100, num_inputs=100, include_existing_trials=include_existing_trials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: still need to update the function generation before running the full benchmark\n",
    "run_benchmark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "await trials.load_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental results: {'000': 9920, '100': 34, '010': 28, '001': 18}\n",
      "Expected: 000\n",
      "Number of matches: 9920\n",
      "Shot count: 10000\n",
      "Function used:\n",
      "def f(x0, x1):\n",
      "    return ((x0) ^ (x0)) and (x1)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# example code to retrieve results from the first trial of 2 variables 2 complexity\n",
    "trial = trials.get(num_vars=2, complexity=2)[0]\n",
    "print(\"Experimental results:\", trial.get_counts())\n",
    "print(\"Expected:\", trial.total_expected_results())\n",
    "print(\"Number of matches:\", trial.get_counts().get(trial.total_expected_results(), 0))\n",
    "print(\"Shot count:\", sum(trial.get_counts().values()))\n",
    "\n",
    "from function_generator import get_python_function\n",
    "print(\"Function used:\", end=\"\")\n",
    "print(get_python_function(trial.statement, trial.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probability data for plotting\n",
    "num_vars_data = []\n",
    "complexity_data = []\n",
    "probability_data = []\n",
    "\n",
    "for num_vars in range(2, 30):\n",
    "        for complexity in range(1, 30):\n",
    "    \n",
    "            successes = 0 \n",
    "            shots = 0\n",
    "            for trial in trials.get(num_vars=num_vars, complexity=complexity):\n",
    "                # TODO: consider using average hamming distance instead of perfect matches\n",
    "                successes += trial.get_counts().get(trial.total_expected_results(), 0)\n",
    "                shots += sum(trial.get_counts().values())\n",
    "            if shots == 0:\n",
    "                 print(f\"Warning: no shots for {num_vars} variables, complexity {complexity}; skipping\")\n",
    "                 continue\n",
    "            \n",
    "            num_vars_data.append(num_vars)\n",
    "            complexity_data.append(complexity)\n",
    "            probability_data.append(successes / shots)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 0.60\n",
    "colors = ['green' if p > threshold else 'red' for p in probability_data]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(num_vars_data, complexity_data, c=colors, edgecolors='black', alpha=0.75)\n",
    "plt.xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "plt.yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "\n",
    "plt.xlabel('Variables Count')\n",
    "plt.ylabel('Complexity')\n",
    "plt.title('Tweedledum & IBM System One Boolean Function Benchmark')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-quantum-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
