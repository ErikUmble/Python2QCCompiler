{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "\n",
    "from benchmarklib import BenchmarkDatabase, _BenchmarkDatabase\n",
    "from rbf import RandomBooleanFunctionTrial, RandomBooleanFunction, _RandomBooleanFunction, _RandomBooleanFunctionTrial\n",
    "from benchmarklib.compilers import CompileType, XAGCompiler, QCFCompiler\n",
    "\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = QiskitRuntimeService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c75ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to load the job results for all trials that are waiting pending job results\n",
    "benchmark_db = BenchmarkDatabase(\"rbf.db\", RandomBooleanFunction, RandomBooleanFunctionTrial)\n",
    "#benchmark_db = _BenchmarkDatabase(\"_rbf.db\", _RandomBooleanFunction, _RandomBooleanFunctionTrial)\n",
    "#await benchmark_db.update_all_pending_results(service, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarklib.analysis import analyze_success_rates\n",
    "from benchmarklib.compilers import TruthTableCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b513c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_data(db, compiler, function_success_threshold, num_vars_iter = range(2, 21), complexity_iter = range(1, 21)):\n",
    "    num_vars_data = []\n",
    "    complexity_data = []\n",
    "    probability_data = []\n",
    "    mean_success_data = []\n",
    "\n",
    "    for num_vars in num_vars_iter:\n",
    "        for complexity in complexity_iter:\n",
    "            print(f\"(num_vars, complexity) = ({num_vars}, {complexity})\")\n",
    "            mean_success_rate = 0.0\n",
    "            successful_function_count = 0\n",
    "            function_count = 0\n",
    "            no_data = True\n",
    "            problem_instances = db.find_problem_instances(num_vars=num_vars, complexity=complexity)\n",
    "            #problem_instances = db.find_problem_instances(size_filters={\"num_vars\": num_vars, \"complexity\": complexity})\n",
    "            trials_by_function = {instance.id: db.find_trials(instance_id=instance.id, compiler_name=compiler.name) for instance in problem_instances}\n",
    "            #trials_by_function = trials.get_per_statement(num_vars=num_vars, complexity=complexity)\n",
    "            for function in trials_by_function.keys():\n",
    "                # skip functions with no trials for this compiler\n",
    "                if len(trials_by_function[function]) == 0:\n",
    "                    continue\n",
    "                function_count += 1\n",
    "                no_data = False\n",
    "                \n",
    "                s = 0.0\n",
    "                for trial in trials_by_function[function]:\n",
    "                    s += trial.calculate_success_rate()\n",
    "                    \n",
    "                if s / len(trials_by_function[function]) > function_success_threshold:\n",
    "                    successful_function_count += 1\n",
    "                mean_success_rate += s / len(trials_by_function[function])\n",
    "\n",
    "            if no_data:\n",
    "                 print(f\"Warning: no results for {num_vars} variables, complexity {complexity}; skipping\")\n",
    "                 continue\n",
    "            \n",
    "            num_vars_data.append(num_vars)\n",
    "            complexity_data.append(complexity)\n",
    "            probability_data.append(successful_function_count / function_count if function_count > 0 else 0)\n",
    "            mean_success_data.append(mean_success_rate / function_count if function_count > 0 else 0)\n",
    "    \n",
    "    return num_vars_data, complexity_data, probability_data\n",
    "\n",
    "def plot_probability_data(num_vars_data, complexity_data, probability_data, title, filepath=None):\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'num_vars': num_vars_data,\n",
    "        'complexity': complexity_data,\n",
    "        'prob': probability_data\n",
    "    })\n",
    "    grid = df.pivot(index='complexity', columns='num_vars', values='prob')\n",
    "    grid = grid.sort_index(ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.pcolormesh(\n",
    "        grid.columns, grid.index, grid.values,\n",
    "        cmap='RdYlGn', shading='auto'\n",
    "    )\n",
    "\n",
    "    plt.xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "    plt.yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "\n",
    "    plt.xlabel('Variables Count')\n",
    "    plt.ylabel('Complexity')\n",
    "    plt.title(title)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(f'Mean Success Rate', rotation=270, labelpad=15)\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_probability_data_side_by_side(num_vars_data, complexity_data, probability_data1, probability_data2, title1, title2, filepath=None):\n",
    "    df1 = pd.DataFrame({\n",
    "        'num_vars': num_vars_data,\n",
    "        'complexity': complexity_data,\n",
    "        'prob': probability_data1\n",
    "    })\n",
    "    grid1 = df1.pivot(index='complexity', columns='num_vars', values='prob')\n",
    "    grid1 = grid1.sort_index(ascending=True)\n",
    "\n",
    "    df2 = pd.DataFrame({\n",
    "        'num_vars': num_vars_data,\n",
    "        'complexity': complexity_data,\n",
    "        'prob': probability_data2\n",
    "    })\n",
    "    grid2 = df2.pivot(index='complexity', columns='num_vars', values='prob')\n",
    "    grid2 = grid2.sort_index(ascending=True)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8))\n",
    "    plot1 = axes[0].pcolormesh(\n",
    "        grid1.columns, grid1.index, grid1.values,\n",
    "        cmap='RdYlGn', shading='auto'\n",
    "    )\n",
    "    axes[0].set_xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "    axes[0].set_yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "    axes[0].set_xlabel('Variables Count')\n",
    "    axes[0].set_ylabel('Complexity')\n",
    "    axes[0].set_title(title1)\n",
    "\n",
    "    plot2 = axes[1].pcolormesh(\n",
    "        grid2.columns, grid2.index, grid2.values,\n",
    "        cmap='RdYlGn', shading='auto'\n",
    "    )\n",
    "    axes[1].set_xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "    axes[1].set_yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "    axes[1].set_xlabel('Variables Count')\n",
    "    axes[1].set_ylabel('Complexity')\n",
    "    axes[1].set_title(title2)\n",
    "\n",
    "    cbar = fig.colorbar(plot1, ax=axes.ravel().tolist(), shrink=0.95)\n",
    "    cbar.set_label(f'Mean Success Rate', rotation=270, labelpad=15)\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_probability_difference(num_vars_data, complexity_data, probability_data1, probability_data2, title, filepath=None):\n",
    "    difference_data = [p1 - p2 for p1, p2 in zip(probability_data1, probability_data2)]\n",
    "    df = pd.DataFrame({\n",
    "        'num_vars': num_vars_data,\n",
    "        'complexity': complexity_data,\n",
    "        'diff': difference_data\n",
    "    })\n",
    "    grid = df.pivot(index='complexity', columns='num_vars', values='diff')\n",
    "    grid = grid.sort_index(ascending=True)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.pcolormesh(\n",
    "        grid.columns, grid.index, grid.values,\n",
    "        cmap='RdBu_r', shading='auto', vmin=-1, vmax=1\n",
    "    )\n",
    "    plt.xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "    plt.yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "\n",
    "    plt.xlabel('Variables Count')\n",
    "    plt.ylabel('Complexity')\n",
    "    plt.title(title)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(f'Difference in Success Rate', rotation=270, labelpad=15)\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate performance data\n",
    "benchmark_db = BenchmarkDatabase(\"rbf.db\", RandomBooleanFunction, RandomBooleanFunctionTrial)\n",
    "num_vars_range = range(2, 21)\n",
    "complexity_range = range(1, 21)\n",
    "num_vars_data, complexity_data, probability_data_qcf = get_probability_data(benchmark_db, compiler=QCFCompiler(), function_success_threshold=0.5, num_vars_iter=num_vars_range, complexity_iter=complexity_range)\n",
    "num_vars_data, complexity_data, probability_data_xag = get_probability_data(benchmark_db, compiler=XAGCompiler(), function_success_threshold=0.5, num_vars_iter=num_vars_range, complexity_iter=complexity_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af558f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "plot_probability_data(num_vars_data, complexity_data, probability_data_qcf, title=\"Probability of Successful Function (QCF Compiler)\", filepath=\"qcf_compiler_success_probability.png\")\n",
    "plot_probability_data(num_vars_data, complexity_data, probability_data_xag, title=\"Probability of Successful Function (XAG Compiler)\", filepath=\"xag_compiler_success_probability.png\")\n",
    "plot_probability_data_side_by_side(num_vars_data, complexity_data, probability_data_qcf, probability_data_xag, title1=\"QCF Compiler\", title2=\"XAG Compiler\", filepath=\"compiler_success_probability_comparison.png\")\n",
    "plot_probability_difference(num_vars_data, complexity_data, probability_data_qcf, probability_data_xag, title=\"Difference in Probability of Success (QCF - XAG)\", filepath=\"compiler_success_probability_difference.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36aa135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_counts_data(num_vars_data, complexity_data, probability_data, title, threshold=None, filepath=None):\n",
    "    if threshold is not None:\n",
    "        colors = ['green' if p > threshold else 'red' for p in probability_data]\n",
    "    else:\n",
    "        colors = probability_data\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(num_vars_data, complexity_data, c=probability_data, cmap='RdYlGn', edgecolors='black', alpha=0.75, s=250)\n",
    "    plt.xticks(np.arange(min(num_vars_data), max(num_vars_data) + 1, 1))\n",
    "    plt.yticks(np.arange(min(complexity_data), max(complexity_data) + 1, 1))\n",
    "\n",
    "    plt.xlabel('Variables Count')\n",
    "    plt.ylabel('Complexity')\n",
    "    plt.title(title)\n",
    "    cbar = plt.colorbar()\n",
    "    if filepath is not None:\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44696f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if compiler.name == CompileType.CLASSICAL_FUNCTION:\n",
    "#    title = \"Qiskit Classical Function on Random Boolean Functions\"\n",
    "#elif compiler.name == CompileType.XAG:\n",
    "#    title = \"Tweedledum XAG on Random Boolean Functions\"\n",
    "#plot_probability_data(num_vars_data_exact, complexity_data_exact, probability_data_exact, title, threshold=0.5, filepath=f'exact_match_rate_{compiler.name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62499ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of functions we have data for, for each number of variables and complexity\n",
    "num_vars_data = []\n",
    "complexity_data = []\n",
    "function_count_data = []\n",
    "\n",
    "for num_vars in range(2, 33):\n",
    "        for complexity in range(1, 22):\n",
    "            with trials._connect() as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute(\"SELECT COUNT(DISTINCT statement) FROM trials WHERE num_vars = ? AND complexity = ? AND NOT counts = ''\", (num_vars, complexity))\n",
    "                count = cursor.fetchone()[0]\n",
    "                num_vars_data.append(num_vars)\n",
    "                complexity_data.append(complexity)\n",
    "                function_count_data.append(count)\n",
    "            print(f\"(num_vars, complexity) = ({num_vars}, {complexity})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8da4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(function_count_data)):\n",
    "    if function_count_data[i] > 30:\n",
    "        function_count_data[i] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_counts_data(num_vars_data, complexity_data, function_count_data, 'Number of functions with data', filepath=f'function_count_{compiler.name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b904b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stddev_data(db, use_hamming=False):\n",
    "    # compute standard deviations of exact match rate across different trials for the same function\n",
    "    \n",
    "    num_vars_data = []\n",
    "    complexity_data = []\n",
    "    all_stddev_data = {}\n",
    "\n",
    "    for num_vars in range(2, 33): # 2 - 32\n",
    "        for complexity in range(1, 22): # 1 - 21\n",
    "            print(f\"(num_vars, complexity) = ({num_vars}, {complexity})\")\n",
    "    \n",
    "            stddev_data = []\n",
    "            no_data = True\n",
    "            problem_instances = db.find_problem_instances(size_filters={'num_vars': num_vars, 'complexity': complexity})\n",
    "            trials_by_function = {instance.instance_id: db.find_trials(instance_id=instance.instance_id, compiler_name=compiler.name) for instance in problem_instances}\n",
    "            #trials_by_function = trials.get_per_statement(num_vars=num_vars, complexity=complexity)\n",
    "\n",
    "            for function in trials_by_function.keys():\n",
    "                # skip functions with no trials for this compiler\n",
    "                if len(trials_by_function[function]) == 0:\n",
    "                    continue\n",
    "\n",
    "                no_data = False\n",
    "                \n",
    "                accuracy_rates = []\n",
    "                for trial in trials_by_function[function]:\n",
    "                    if use_hamming:\n",
    "                        accuracy_rates.append(1-trial.mean_hamming_distance)\n",
    "                    else:\n",
    "                        accuracy_rates.append(trial.result_qubit_success_rate)\n",
    "\n",
    "                stddev_data.append(np.std(accuracy_rates))\n",
    "                    \n",
    "            if no_data:\n",
    "                 print(f\"Warning: no results for {num_vars} variables, complexity {complexity}; skipping\")\n",
    "                 continue\n",
    "            \n",
    "            num_vars_data.append(num_vars)\n",
    "            complexity_data.append(complexity)\n",
    "            all_stddev_data[(num_vars, complexity)] = stddev_data\n",
    "\n",
    "    return all_stddev_data, num_vars_data, complexity_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev_data, num_vars_data_stddev, complexity_data_stddev = get_stddev_data(benchmark_db, use_hamming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in stddev_data.items():\n",
    "    print(f\"{key}: {np.mean(value)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedledum-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
