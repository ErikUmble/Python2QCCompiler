{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from sqlalchemy.orm import joinedload\n",
    "\n",
    "from benchmarklib import BenchmarkDatabase\n",
    "from rbf import RandomBooleanFunctionTrial, RandomBooleanFunction\n",
    "from benchmarklib.compilers import CompileType, XAGCompiler\n",
    "\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, RuntimeJobNotFound\n",
    "\n",
    "import logging\n",
    "from typing import Iterable, List, Tuple, Dict, Any, Union, Optional\n",
    "import qiskit\n",
    "from qiskit.providers import Backend\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "import random\n",
    "\n",
    "from tweedledum.bool_function_compiler import circuit_input, QuantumCircuitFunction\n",
    "from tweedledum import BitVec\n",
    "\n",
    "from sqlalchemy import select, func\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from benchmarklib import CompileType, BenchmarkDatabase\n",
    "from benchmarklib import BatchQueue\n",
    "from benchmarklib.compilers import SynthesisCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_TOKEN_OLD = os.getenv(\"API_TOKEN_OLD\")\n",
    "API_INSTANCE_OLD = os.getenv(\"API_INSTANCE_OLD\")\n",
    "service = QiskitRuntimeService()  # default service with new credentials\n",
    "service_old = QiskitRuntimeService(\n",
    "    channel='ibm_quantum_platform',\n",
    "    token=API_TOKEN_OLD,\n",
    "    instance=API_INSTANCE_OLD\n",
    ")\n",
    "backend = service.backend(\"ibm_rensselaer\")\n",
    "benchmark_db = BenchmarkDatabase(\"rbf.db\", RandomBooleanFunction, RandomBooleanFunctionTrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import RuntimeJobFailureError\n",
    "\n",
    "# Async Job Management\n",
    "def get_missing_circuit_job_ids(db_manager) -> List[str]:\n",
    "    \"\"\"Get all job IDs with pending results.\"\"\"\n",
    "    with db_manager.session() as session:\n",
    "        query = (\n",
    "            select(db_manager.trial_class.job_id)\n",
    "            .where(\n",
    "                db_manager.trial_class.job_id != None,\n",
    "                db_manager.trial_class.circuit_depth == None,\n",
    "                db_manager.trial_class.is_failed == False\n",
    "            )\n",
    "            .distinct()\n",
    "            .limit(1000)\n",
    "        )\n",
    "        results = session.execute(query).scalars().all()\n",
    "        return list(results)\n",
    "\n",
    "async def update_job_results(db_manager, job_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Fetch and update results for a specific job.\n",
    "\n",
    "    Args:\n",
    "        job_id: IBM Quantum job ID\n",
    "        service: QiskitRuntimeService instance\n",
    "    \"\"\"\n",
    "    \n",
    "    job = None\n",
    "    for svc in [service, service_old]:  # try each service in order until job is found\n",
    "        try:\n",
    "            job = await asyncio.to_thread(svc.job, job_id)\n",
    "            break\n",
    "        except RuntimeJobNotFound:\n",
    "            continue\n",
    "    \n",
    "    if job is None:\n",
    "        # Handle the case where job wasn't found in any service\n",
    "        print(f\"Job not found in any service for trial {trial}\")\n",
    "        return\n",
    "    \n",
    "    # Update all trials for this job\n",
    "    trials = db_manager.find_trials(job_id=job_id, circuit_depth=None, is_failed=False)\n",
    "    updated_count = 0\n",
    "\n",
    "    with db_manager.session() as session:\n",
    "        for trial in trials:\n",
    "            circuit = job.inputs['pubs'][trial.job_pub_idx][0]\n",
    "            trial.load_circuit_metrics(circuit=circuit)\n",
    "            session.merge(trial)\n",
    "            updated_count += 1\n",
    "        session.commit()\n",
    "\n",
    "        print(f\"Updated {updated_count} trials for job {job_id}\")\n",
    "\n",
    "async def update_all_pending_results(db_manager, batch_size: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Update all pending job results asynchronously.\n",
    "\n",
    "    Args:\n",
    "        service: QiskitRuntimeService instance\n",
    "        batch_size: Number of concurrent job fetches\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        pending_jobs = get_missing_circuit_job_ids(db_manager)\n",
    "        if len(pending_jobs) == 0:\n",
    "            break\n",
    "\n",
    "        print(f\"Updating circuits from {len(pending_jobs)} jobs\")\n",
    "\n",
    "        # Process jobs in batches to avoid overwhelming the API\n",
    "        for i in range(0, len(pending_jobs), batch_size):\n",
    "            batch = pending_jobs[i : i + batch_size]\n",
    "            tasks = [update_job_results(db_manager, job_id) for job_id in batch]\n",
    "\n",
    "            batch_num = i // batch_size + 1\n",
    "            total_batches = (len(pending_jobs) + batch_size - 1) // batch_size\n",
    "            print(f\"Processing batch {batch_num}/{total_batches}\")\n",
    "\n",
    "            await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "await update_all_pending_results(benchmark_db, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1aadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-threaded fetching circuits from IBM Quantum jobs\n",
    "async def load_and_save_circuit_metrics(trial: RandomBooleanFunctionTrial):\n",
    "    if trial.circuit_depth is None:\n",
    "        circuit = None\n",
    "        for svc in [service, service_old]:  # try each service in order until job is found\n",
    "            try:\n",
    "                circuit = await trial.get_ibm_circuit(svc)\n",
    "                trial.load_circuit_metrics(circuit=circuit)\n",
    "                break\n",
    "            except RuntimeJobNotFound:\n",
    "                continue\n",
    "        \n",
    "        if circuit is None:\n",
    "            # Handle the case where job wasn't found in any service\n",
    "            print(f\"Job not found in any service for trial {trial}\")\n",
    "            return\n",
    "            \n",
    "        benchmark_db.save_trial(trial)\n",
    "\n",
    "for num_vars in range(2, 31):\n",
    "    for complexity in range(1, 21):\n",
    "        print(num_vars, complexity)\n",
    "        batch_size = max(5, 50 - (num_vars * complexity))\n",
    "        missing_trial_count = benchmark_db.query(\n",
    "            select(func.count(RandomBooleanFunctionTrial.id))\n",
    "            .select_from(RandomBooleanFunctionTrial).join(RandomBooleanFunction)\n",
    "            .where(RandomBooleanFunctionTrial.circuit_depth == None, RandomBooleanFunction.num_vars == num_vars, RandomBooleanFunction.complexity == complexity, RandomBooleanFunctionTrial.is_failed == False)\n",
    "        )[0]\n",
    "        if missing_trial_count == 0:\n",
    "            continue\n",
    "        for _ in range(missing_trial_count // batch_size + 1):\n",
    "            tasks = [load_and_save_circuit_metrics(trial) for trial in benchmark_db.query(\n",
    "                select(RandomBooleanFunctionTrial)\n",
    "                .join(RandomBooleanFunction)\n",
    "                .where(RandomBooleanFunctionTrial.circuit_depth == None, RandomBooleanFunctionTrial.is_failed == False)\n",
    "                .limit(batch_size)\n",
    "            )]\n",
    "            asyncio.run(asyncio.wait(tasks))\n",
    "            print(f\"Completed {(_+1)*batch_size}/{missing_trial_count} trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f840546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-threaded fetching circuits from IBM Quantum jobs\n",
    "async def load_and_save_circuit_metrics(trial: RandomBooleanFunctionTrial):\n",
    "    if trial.circuit_depth is None:\n",
    "        circuit = None\n",
    "        for svc in [service, service_old]:  # try each service in order until job is found\n",
    "            try:\n",
    "                circuit = await trial.get_ibm_circuit(svc)\n",
    "                trial.load_circuit_metrics(circuit=circuit)\n",
    "                break\n",
    "            except RuntimeJobNotFound:\n",
    "                continue\n",
    "        \n",
    "        if circuit is None:\n",
    "            # Handle the case where job wasn't found in any service\n",
    "            print(f\"Job not found in any service for trial {trial}\")\n",
    "            return\n",
    "            \n",
    "        benchmark_db.save_trial(trial)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "target_trial_count = 4000\n",
    "current_trial_count= benchmark_db.query(\n",
    "    select(func.count(RandomBooleanFunctionTrial.id))\n",
    "    .where(RandomBooleanFunctionTrial.circuit_depth != None)\n",
    ")[0]\n",
    "for _ in range((target_trial_count - current_trial_count) // BATCH_SIZE + 1):\n",
    "    tasks = [load_and_save_circuit_metrics(trial) for trial in benchmark_db.query(\n",
    "        select(RandomBooleanFunctionTrial)\n",
    "        .join(RandomBooleanFunction)\n",
    "        .where(RandomBooleanFunctionTrial.circuit_depth == None, RandomBooleanFunctionTrial.is_failed == False)\n",
    "        .order_by(func.random())\n",
    "        .limit(BATCH_SIZE)\n",
    "    )]\n",
    "    asyncio.run(asyncio.wait(tasks))\n",
    "    print(f\"Completed {current_trial_count + _*BATCH_SIZE}/{target_trial_count} trials\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "X = np.ones((1000, 7))\n",
    "Y = np.zeros((1000, 1))\n",
    "X_test = np.ones((100, 7))\n",
    "Y_test = np.zeros((100, 1))\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "for i, trial in enumerate(benchmark_db.query(\n",
    "    select(RandomBooleanFunctionTrial)\n",
    "    .where(RandomBooleanFunctionTrial.circuit_depth != None)\n",
    "    .order_by(func.random())\n",
    "    .limit(X.shape[0] + X_test.shape[0])\n",
    "    .options(joinedload(RandomBooleanFunctionTrial.problem))\n",
    ")):\n",
    "    if i < 1000:\n",
    "        X[i, 1] = trial.circuit_num_qubits\n",
    "        X[i, 2] = trial.circuit_depth\n",
    "        X[i, 3] = trial.circuit_op_counts.get('ecr', 0)\n",
    "        X[i, 4] = trial.circuit_op_counts.get('rz', 0)\n",
    "        X[i, 5] = trial.circuit_op_counts.get('sx', 0)\n",
    "        X[i, 6] = trial.circuit_op_counts.get('x', 0)\n",
    "        \n",
    "        Y[i, 0] = trial.calculate_success_rate()\n",
    "        train_ids.append(trial.id)\n",
    "    else:\n",
    "        X_test[i-1000, 0] = trial.circuit_num_qubits\n",
    "        X_test[i-1000, 1] = trial.circuit_depth\n",
    "        X_test[i-1000, 2] = trial.circuit_op_counts.get('ecr', 0)\n",
    "        X_test[i-1000, 3] = trial.circuit_op_counts.get('rz', 0)\n",
    "        X_test[i-1000, 4] = trial.circuit_op_counts.get('sx', 0)\n",
    "        X_test[i-1000, 5] = trial.circuit_op_counts.get('x', 0)\n",
    "\n",
    "        Y_test[i-1000, 0] = trial.calculate_success_rate()\n",
    "        test_ids.append(trial.id)\n",
    "\n",
    "# save datasets to disk for reproducibility\n",
    "np.save(\"train_features.npy\", X)\n",
    "np.save(\"train_labels.npy\", Y)\n",
    "np.save(\"test_features.npy\", X_test)\n",
    "np.save(\"test_labels.npy\", Y_test)\n",
    "\n",
    "with open(\"train_ids.json\", \"w\") as f:\n",
    "    json.dump(train_ids, f)\n",
    "with open(\"test_ids.json\", \"w\") as f:\n",
    "    json.dump(test_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"train_features.npy\")\n",
    "Y = np.load(\"train_labels.npy\")\n",
    "X_test = np.load(\"test_features.npy\")\n",
    "Y_test = np.load(\"test_labels.npy\")\n",
    "\n",
    "# use logistic regression to predict success rate\n",
    "model = LogisticRegression(max_iter=10, )\n",
    "model.fit(X, np.round(Y).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449875a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "Y_pred = model.predict(X)\n",
    "confusion_matrix_in = confusion_matrix(np.round(Y), Y_pred)\n",
    "cross_entropy_in = log_loss(np.round(Y), model.predict_proba(X)) / len(Y)\n",
    "print(\"In-sample Confusion Matrix:\")\n",
    "print(confusion_matrix_in)\n",
    "print(f\"In-sample Error (Cross Entropy): {cross_entropy_in}\")\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "confusion_matrix_out = confusion_matrix(np.round(Y_test), Y_pred)\n",
    "cross_entropy_out = log_loss(np.round(Y_test), model.predict_proba(X_test)) / len(Y_test)\n",
    "print(\"Out-of-sample Confusion Matrix:\")\n",
    "print(confusion_matrix_out)\n",
    "print(f\"Out-of-sample Error (Cross Entropy): {cross_entropy_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(np.round(Y_test).ravel().astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coef, name in zip(model.coef_[0], \n",
    "                    [\"Bias\", \"Num Qubits\", \"Circuit Depth\", \"ECR Count\", \"RZ Count\", \"SX Count\", \"X Count\"]):\n",
    "    print(f\"{name}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa491dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = backend.properties()\n",
    "error_rates = {}\n",
    "for g in backend.configuration().basis_gates:\n",
    "    error_rates[g] = []\n",
    "    for gate_info in properties.gates:\n",
    "        d = gate_info.to_dict()\n",
    "        if d[\"gate\"] == g:\n",
    "            for param in d[\"parameters\"]:\n",
    "                if param[\"name\"] == \"gate_error\":\n",
    "                    error_rates[g].append(param[\"value\"])\n",
    "for g in error_rates:\n",
    "    if len(error_rates[g]) > 0:\n",
    "        print(f\"{g}: avg error = {np.mean(error_rates[g]):.2e} (min={np.min(error_rates[g]):.2e}, max={np.max(error_rates[g]):.2e})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(np.linspace(0, 1, 10), np.round(Y, 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweedledum-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
